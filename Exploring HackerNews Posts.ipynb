{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "# Analyzing Hacker News Posts Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacker News is a platform, extremely popular in technology and startup circles, where users share their posts and receives some votes and comments. We would be analyzing these posts along with some additional data like date of creation, upvotes, comments and so on, to derive some useful insights. The [data set]('https://www.kaggle.com/hacker-news/hacker-news-posts') used has been cut down from almost 300,000 rows to approximately 20,000 rows for our analysis purposes by removing those posts' data which have incomplete information such as zero comments or upvotes.\n",
    "\n",
    "The columns of the data set are as follows:\n",
    "\n",
    "| Column  |About |\n",
    "|:--------|:------|\n",
    "|id | the unique identifier from Hacker News for the post|\n",
    "|title | the title of the post|\n",
    "|url | the URL that the posts links to, if the post has a URL|\n",
    "|num_points| the number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes|\n",
    "|num_comments | the number of comments on the post|\n",
    "|author | the username of the person who submitted the post|\n",
    "|created_at | the date and time of the post's submission|\n",
    "\n",
    "We are specifically interested in posts beggining with `Ask HN` or `Show HN`. `Ask HN` are the posts in which users asks a question to the other users on Hacker News and `Show HN` are the posts in which users showcase something of their own or just anything interesting. \n",
    "\n",
    "We would be comparing these two posts to determine the following:\n",
    "* Do `Ask HN` or `Show HN` receive more comments on average?\n",
    "* Do posts created at a certain time receive more comments on average?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Importing the required Hacker News data set__\n",
    "\n",
    "Let's start by importing the data set, `hacker_news.csv` as a list of lists and storing it in `hn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'],\n",
       " ['12224879',\n",
       "  'Interactive Dynamic Video',\n",
       "  'http://www.interactivedynamicvideo.com/',\n",
       "  '386',\n",
       "  '52',\n",
       "  'ne0phyte',\n",
       "  '8/4/2016 11:52'],\n",
       " ['10975351',\n",
       "  'How to Use Open Source and Shut the Fuck Up at the Same Time',\n",
       "  'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/',\n",
       "  '39',\n",
       "  '10',\n",
       "  'josep2',\n",
       "  '1/26/2016 19:30'],\n",
       " ['11964716',\n",
       "  \"Florida DJs May Face Felony for April Fools' Water Joke\",\n",
       "  'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/',\n",
       "  '2',\n",
       "  '1',\n",
       "  'vezycash',\n",
       "  '6/23/2016 22:20'],\n",
       " ['11919867',\n",
       "  'Technology ventures: From Idea to Enterprise',\n",
       "  'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429',\n",
       "  '3',\n",
       "  '1',\n",
       "  'hswarna',\n",
       "  '6/17/2016 0:01']]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing 'reader' from 'csv' module\n",
    "from csv import reader\n",
    "\n",
    "# Opening the file and creating a 'reader' object\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "\n",
    "hn = list(read_file)\n",
    "hn[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, the above data set contains the header columns list as the first row, we will remove it from the set and store it in the `headers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "# Storing headers of data in a variable\n",
    "headers = hn[0]\n",
    "\n",
    "# Assigning the data set with minus header row\n",
    "hn = hn[1:]\n",
    "\n",
    "# Inspecting the data set\n",
    "print(headers)\n",
    "print('\\n')\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data cleaning__\n",
    "\n",
    "Now that we have the data set, let's start preparing it for analysis. Since, we require posts that either starts with `Ask HN` or `Show HN`, we will isolate this data in other lists. We will use a string method `string.startswith('word')` to check whether a string starts with provided phrase or word. It will return `True` if it does, otherwise `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask HN posts: 1744\n",
      "[['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55'], ['10610020', 'Ask HN: Am I the only one outraged by Twitter shutting down share counts?', '', '28', '29', 'tkfx', '11/22/2015 13:43']]\n",
      "\n",
      "\n",
      "Show HN posts: 1162\n",
      "[['10627194', 'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform', 'https://iot.seeed.cc', '26', '22', 'kfihihc', '11/25/2015 14:03'], ['10646440', 'Show HN: Something pointless I made', 'http://dn.ht/picklecat/', '747', '102', 'dhotson', '11/29/2015 22:46']]\n",
      "\n",
      "\n",
      "Other posts: 17194\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']]\n"
     ]
    }
   ],
   "source": [
    "# Defining some empty lists\n",
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "# Looping over hn \n",
    "for row in hn:\n",
    "    \n",
    "    # Extracting the title and converting it to lower case\n",
    "    title = row[1].lower()\n",
    "    \n",
    "    # Checking whether the title starts with 'ask hn' or 'show hn' \n",
    "    # and appending in respective lists.\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "\n",
    "print('Ask HN posts:',len(ask_posts))\n",
    "print(ask_posts[:2])\n",
    "print('\\n')\n",
    "print('Show HN posts:',len(show_posts))\n",
    "print(show_posts[:2])\n",
    "print('\\n')\n",
    "print('Other posts:',len(other_posts))\n",
    "print(other_posts[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Finding the average number of comments on `Ask HN` and `Show HN` posts__\n",
    "\n",
    "Now that we have different data for the `Ask HN` and `Show HN`, we can now start analysing data. We will determine whether `Ask HN` or `Show HN` posts receive more comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id : <class 'str'>\n",
      "title : <class 'str'>\n",
      "url : <class 'str'>\n",
      "num_points : <class 'str'>\n",
      "num_comments : <class 'str'>\n",
      "author : <class 'str'>\n",
      "created_at : <class 'str'>\n",
      "\n",
      "\n",
      "Average Ask HN comments : 14.04\n",
      "Average Show HN comments : 10.32\n"
     ]
    }
   ],
   "source": [
    "# Investigating the headers' data types\n",
    "for column in headers:\n",
    "    print(column,':',type(column))\n",
    "\n",
    "# Finding the average number of comments for:\n",
    "# 1) 'Ask HN' posts\n",
    "total_ask_comments = 0\n",
    "for row in ask_posts:\n",
    "    num_comment = int(row[4])\n",
    "    total_ask_comments += num_comment\n",
    "\n",
    "print('\\n')    \n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "print('Average Ask HN comments : {:.2f}'.format(avg_ask_comments))\n",
    "\n",
    "# 2) 'Show HN' posts\n",
    "total_show_comments = 0\n",
    "for row in show_posts:\n",
    "    num_comment = int(row[4])\n",
    "    total_show_comments += num_comment\n",
    "    \n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "print('Average Show HN comments : {:.2f}'.format(avg_show_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is evident from the above output, the average number of comments on `Ask HN` are greater than the `Show HN` posts. The reason could be because of the nature of `Ask HN` post which is basically a question being asked and thus engross much more audience as compared to the the `Show HN` post which is more like a general discussion, statement or a fact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Determining the most popular post-creation time__\n",
    "\n",
    "Since the `Ask HN` posts seems more popular, we would continue our analysis on those only. We will determine if `Ask HN` posts created at certain time are more likely to attract comments. We'll use the following steps to perform this analysis:\n",
    "* Calculate the number of `Ask HN` posts created in each hour of the day.\n",
    "* Calculate the average number of comments `Ask HN` posts receive by hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample from result_list: [['8/16/2016 9:55', 6], ['11/22/2015 13:43', 29]]\n",
      "\n",
      "\n",
      "Posts per hour: {'09': 45, '13': 85, '10': 59, '14': 107, '16': 108, '23': 68, '12': 73, '17': 100, '15': 116, '21': 109, '20': 80, '02': 58, '18': 109, '03': 54, '05': 46, '19': 110, '01': 60, '22': 71, '08': 48, '04': 47, '00': 55, '06': 44, '07': 34, '11': 58}\n",
      "\n",
      "\n",
      "Comments per hour: {'09': 251, '13': 1253, '10': 793, '14': 1416, '16': 1814, '23': 543, '12': 687, '17': 1146, '15': 4477, '21': 1745, '20': 1722, '02': 1381, '18': 1439, '03': 421, '05': 464, '19': 1188, '01': 683, '22': 479, '08': 492, '04': 337, '00': 447, '06': 397, '07': 267, '11': 641}\n"
     ]
    }
   ],
   "source": [
    "# Importing required 'datetime' module\n",
    "import datetime as dt\n",
    "\n",
    "# Initializing an empty list for date of post creation and number of comments\n",
    "# on the post\n",
    "result_list = []\n",
    "\n",
    "# Looping over 'Ask HN' posts\n",
    "for row in ask_posts:\n",
    "    \n",
    "    # Storing the date and comments in variables\n",
    "    created_at = row[-1]\n",
    "    num_comments = int(row[-3])\n",
    "    \n",
    "    # Appending the above data to the list created before\n",
    "    result_list.append([created_at, num_comments])\n",
    "print('Sample from result_list:',result_list[:2])    \n",
    "print('\\n')\n",
    "\n",
    "# Initializing two empty dictionaries for creating a frequency table for number\n",
    "# of posts created per given hour and number of comments on the posts at each\n",
    "# hour\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "for row in result_list:\n",
    "    \n",
    "    # Creating a datetime object from the string datetime column\n",
    "    date_parsed = dt.datetime.strptime(row[0],'%m/%d/%Y %H:%M') \n",
    "    \n",
    "    # Formatting the datetime object to obtain hour as string\n",
    "    hr=date_parsed.strftime('%H')\n",
    "    \n",
    "    # Checking whether the above 'hour' exists as a key in the dictionaries or not\n",
    "    # and updating the both the dictionaries as follows:\n",
    "    # if hr exists in counts_by_hr then:\n",
    "    #    update the key-value pair of hr in both dictionaries by 1\n",
    "    # else:\n",
    "    #    create the key-value pair of hr in both dictionaries with initialization at 1\n",
    "    if hr in counts_by_hour:\n",
    "        counts_by_hour[hr] += 1\n",
    "        comments_by_hour[hr] += row[1]\n",
    "    else:\n",
    "        counts_by_hour[hr] = 1\n",
    "        comments_by_hour[hr] = row[1]\n",
    "        \n",
    "print('Posts per hour:',counts_by_hour)\n",
    "print('\\n')\n",
    "print('Comments per hour:',comments_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Calculating the average number of comments per `Ask HN` post for each hour__\n",
    "\n",
    "Now that we have the data of number of posts and comments per hour, we can determine the average number of comments on a post for a given hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['09', 5.5777777777777775], ['13', 14.741176470588234], ['10', 13.440677966101696], ['14', 13.233644859813085], ['16', 16.796296296296298], ['23', 7.985294117647059], ['12', 9.41095890410959], ['17', 11.46], ['15', 38.5948275862069], ['21', 16.009174311926607], ['20', 21.525], ['02', 23.810344827586206], ['18', 13.20183486238532], ['03', 7.796296296296297], ['05', 10.08695652173913], ['19', 10.8], ['01', 11.383333333333333], ['22', 6.746478873239437], ['08', 10.25], ['04', 7.170212765957447], ['00', 8.127272727272727], ['06', 9.022727272727273], ['07', 7.852941176470588], ['11', 11.051724137931034]]\n"
     ]
    }
   ],
   "source": [
    "# Initializing an empty list for storing average number of comments per post\n",
    "# for each hour i.e., number of comments per post per hour / num of posts per \n",
    "# hour\n",
    "avg_by_hour = []\n",
    "for post in counts_by_hour:\n",
    "    avg_comments_per_post = comments_by_hour[post] / counts_by_hour[post]\n",
    "    \n",
    "    # Appending the data, time and averaged comments to the above list\n",
    "    avg_by_hour.append([post,avg_comments_per_post])\n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sorting the data for better accessibility and readability__\n",
    "\n",
    "Now that we have the data, we can finally make a decision on the hour of the day on which the most comments were posted on a post. But the values are not easy to read since data is not sorted. Let's do so by swapping the values in each row of the above list and storing them in another list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swapped list of data\n",
      "[5.5777777777777775, '09']\n",
      "[14.741176470588234, '13']\n",
      "[13.440677966101696, '10']\n",
      "[13.233644859813085, '14']\n",
      "[16.796296296296298, '16']\n",
      "[7.985294117647059, '23']\n",
      "[9.41095890410959, '12']\n",
      "[11.46, '17']\n",
      "[38.5948275862069, '15']\n",
      "[16.009174311926607, '21']\n",
      "[21.525, '20']\n",
      "[23.810344827586206, '02']\n",
      "[13.20183486238532, '18']\n",
      "[7.796296296296297, '03']\n",
      "[10.08695652173913, '05']\n",
      "[10.8, '19']\n",
      "[11.383333333333333, '01']\n",
      "[6.746478873239437, '22']\n",
      "[10.25, '08']\n",
      "[7.170212765957447, '04']\n",
      "[8.127272727272727, '00']\n",
      "[9.022727272727273, '06']\n",
      "[7.852941176470588, '07']\n",
      "[11.051724137931034, '11']\n",
      "\n",
      "\n",
      "Sorting the above data\n",
      "[38.5948275862069, '15']\n",
      "[23.810344827586206, '02']\n",
      "[21.525, '20']\n",
      "[16.796296296296298, '16']\n",
      "[16.009174311926607, '21']\n",
      "[14.741176470588234, '13']\n",
      "[13.440677966101696, '10']\n",
      "[13.233644859813085, '14']\n",
      "[13.20183486238532, '18']\n",
      "[11.46, '17']\n",
      "[11.383333333333333, '01']\n",
      "[11.051724137931034, '11']\n",
      "[10.8, '19']\n",
      "[10.25, '08']\n",
      "[10.08695652173913, '05']\n",
      "[9.41095890410959, '12']\n",
      "[9.022727272727273, '06']\n",
      "[8.127272727272727, '00']\n",
      "[7.985294117647059, '23']\n",
      "[7.852941176470588, '07']\n",
      "[7.796296296296297, '03']\n",
      "[7.170212765957447, '04']\n",
      "[6.746478873239437, '22']\n",
      "[5.5777777777777775, '09']\n",
      "\n",
      "\n",
      "Top 5 hours for Ask HN posts\n",
      "15:00 EST: 38.59 average comments per post\n",
      "02:00 EST: 23.81 average comments per post\n",
      "20:00 EST: 21.52 average comments per post\n",
      "16:00 EST: 16.80 average comments per post\n",
      "21:00 EST: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "# Initializing an empty list for creating a swapped list\n",
    "swap_avg_by_hour = []\n",
    "for row in avg_by_hour:\n",
    "    \n",
    "    # Swapping and appending the values\n",
    "    swap_avg_by_hour.append([row[1],row[0]])\n",
    "\n",
    "print('Swapped list of data')    \n",
    "for row in swap_avg_by_hour:\n",
    "    print(row)\n",
    "        \n",
    "print('\\n')\n",
    "\n",
    "# Printing a sorted list of above data in descending order of average comments\n",
    "sorted_swap = sorted(swap_avg_by_hour,reverse=True)\n",
    "print('Sorting the above data')\n",
    "for row in sorted_swap:\n",
    "    print(row)\n",
    "\n",
    "# Printing the top 5 values out of the above list\n",
    "print('\\n')\n",
    "print('Top 5 hours for Ask HN posts')\n",
    "for row in sorted_swap[:5]:\n",
    "    hour = row[1]\n",
    "    avg_comments = row[0]\n",
    "    parsed_date = dt.datetime.strptime(hour,'%H')\n",
    "    converted_date = parsed_date.strftime('%H:%M')\n",
    "    \n",
    "    print('{} EST: {:.2f} average comments per post'.format(converted_date,avg_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above results suggests that the time period from `15:00 to 16:00 EST` that is Eastern Standard Time, receives the highest number of comments on the `Ask HN` posts. To understand it in the terms of `IST` that is, `Indian Standard Time` let's do a conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 hours for Ask HN post in Indian Standard Time\n",
      "01:00 IST: 38.59 average comments per post\n",
      "12:00 IST: 23.81 average comments per post\n",
      "06:00 IST: 21.52 average comments per post\n",
      "02:00 IST: 16.80 average comments per post\n",
      "07:00 IST: 16.01 average comments per post\n",
      "Hour with least comments: 19:00 IST with 5.58 comments\n"
     ]
    }
   ],
   "source": [
    "# Initializing an empty list for storing IST values\n",
    "ist_data = []\n",
    "\n",
    "# Importing 'pytz' module for defining the timezone of original values as 'EST'\n",
    "import pytz\n",
    "for row in sorted_swap:\n",
    "    avg_comment = row[0]\n",
    "    time = row[1]\n",
    "    \n",
    "    # Parsing the date from string as hour only \n",
    "    parse_time = dt.datetime.strptime(time,'%H')\n",
    "    \n",
    "    # Replacing the naive 'datetime' object with 'active' datetime object with\n",
    "    # 'UST' timezone\n",
    "    est_tz = parse_time.replace(tzinfo=pytz.timezone('US/Eastern'))\n",
    "    \n",
    "    # Converting the timezone: EST to IST\n",
    "    changed_tz = est_tz.astimezone(pytz.timezone('Asia/Kolkata'))\n",
    "    \n",
    "    # Finally appending the data to the list as formatted string\n",
    "    final_ist = changed_tz.strftime('%H:00')\n",
    "    ist_data.append([avg_comment,final_ist])\n",
    "\n",
    "# printing the top 5 and the least average number of comments posts\n",
    "print('Top 5 hours for Ask HN post in Indian Standard Time')    \n",
    "for row in ist_data[:5]:\n",
    "        time_data = row[1]\n",
    "        avg_comment = row[0]\n",
    "        print('{} IST: {:.2f} average comments per post'.format(time_data,avg_comment))\n",
    "print('Hour with least comments: {} IST with {:.2f} comments'.format(ist_data[-1][-1],ist_data[-1][0]))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data seems to be much better. It can be easily deduced that difference between the hour with maximum average number of comments and the minimum average number of comments comes at a percentage difference of approximately `30%`, which is quite significant. Hence, we can say that the timings of post creation does infact impacts the number of comments and thus audience engagement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this project, we analyzed `Ask HN` posts and `Show HN` posts to determine which type of post and time receive the most comments on average. Based on our analysis, to maximize the amount of comments a post receives, we'd recommend the post be categorized as `Ask HN` post and created between `15:00 and 16:00 EST` `(1:00 and 2:00 IST)`\n",
    "\n",
    "However, it should be noted that the data set we analyzed excluded posts without any comments. Given that, it's more accurate to say that of the posts that received comments, `Ask HN` posts received more comments on average and `Ask HN` posts created between `15:00 and 16:00 EST` `(1:00 and 2:00 IST)` received the most comments on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some more useful insights from the data set\n",
    "1. __Determining if `Show HN` or `Ask HN` receives more points on average__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average 'Ask HN' points : 15.06\n",
      "Average 'Show HN' points : 27.56\n"
     ]
    }
   ],
   "source": [
    "# Initializing two lists to store posts' titles and points\n",
    "ask_points = []\n",
    "show_points = []\n",
    "\n",
    "# Appending required data\n",
    "for row in ask_posts:\n",
    "    ask_points.append([row[1],int(row[3])])\n",
    "for row in show_posts:\n",
    "    show_points.append([row[1],int(row[3])])\n",
    "\n",
    "# Calculating average points for Ask HN posts    \n",
    "summed = 0    \n",
    "for row in ask_points:\n",
    "    point = row[1]\n",
    "    summed += point\n",
    "avg_ask_points = summed / len(ask_points)\n",
    "\n",
    "# Calculating average points for Show HN posts\n",
    "summed = 0    \n",
    "for row in show_points:\n",
    "    point = row[1]\n",
    "    summed += point\n",
    "avg_show_points = summed / len(show_points)\n",
    "\n",
    "print('Average \\'Ask HN\\' points : {:.2f}'.format(avg_ask_points))\n",
    "print('Average \\'Show HN\\' points : {:.2f}'.format(avg_show_points))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear from the above output that the `Show HN` posts have greater points as compared to `Ask HN` posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. __Determining if posts created at a certain time are more likely to receive more points__\n",
    "\n",
    "Since, `Show HN` posts have more number of average points, we will restrict our analysis to these only. In order to find out whether the posts created at certain time receive more points, we will do the following:\n",
    "* Determining the number of `Show HN` posts created at different hours.\n",
    "* Determining the average number of points received on the `Show HN` posts at particular hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data: [[datetime.datetime(2015, 11, 25, 14, 3), 26], [datetime.datetime(2015, 11, 29, 22, 46), 747], [datetime.datetime(2016, 4, 28, 18, 5), 1], [datetime.datetime(2016, 7, 28, 7, 11), 3], [datetime.datetime(2016, 1, 9, 20, 45), 1]]\n",
      "\n",
      "\n",
      "Posts per hour: {'14': 86, '22': 46, '18': 61, '07': 26, '20': 60, '05': 19, '16': 93, '19': 55, '15': 78, '03': 27, '17': 93, '06': 16, '02': 30, '13': 99, '08': 34, '21': 47, '04': 26, '11': 44, '12': 61, '23': 36, '09': 30, '01': 28, '10': 36, '00': 31}\n",
      "\n",
      "\n",
      "Points per hour: {'14': 2187, '22': 1856, '18': 2215, '07': 494, '20': 1819, '05': 104, '16': 2634, '19': 1702, '15': 2228, '03': 679, '17': 2521, '06': 375, '02': 340, '13': 2438, '08': 519, '21': 866, '04': 386, '11': 1480, '12': 2543, '23': 1526, '09': 553, '01': 700, '10': 681, '00': 1173}\n"
     ]
    }
   ],
   "source": [
    "# Initializing a list for storing Show HN posts' creation time and points\n",
    "mod_show_posts = []\n",
    "\n",
    "# Looping over Show HN posts data set and collecting required columns\n",
    "for row in show_posts:\n",
    "    date_post = row[-1]\n",
    "    points_post = int(row[3])\n",
    "    \n",
    "    # Parsing the date using datetime.strptime() method \n",
    "    date_post = dt.datetime.strptime(date_post,'%m/%d/%Y %H:%M')\n",
    "    \n",
    "    # Appending the data to the above list\n",
    "    mod_show_posts.append([date_post,points_post])\n",
    "\n",
    "# Checking the data set\n",
    "print('Sample data:',mod_show_posts[:5])\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Initializing two empty dictionaries for creating frequency tables for number\n",
    "# of posts created per hour and number of points received per hour per\n",
    "show_by_hour = {}\n",
    "points_by_hour = {}\n",
    "\n",
    "\n",
    "for row in mod_show_posts:\n",
    "    points = row[1]\n",
    "    date = row[0]\n",
    "    \n",
    "    # Extracting the hour out of the datetime object\n",
    "    hour = date.strftime('%H')\n",
    "    \n",
    "    # Checking if hour exists as a key in both dictionaries\n",
    "    if hour in show_by_hour:\n",
    "        show_by_hour[hour] += 1\n",
    "        points_by_hour[hour] += points\n",
    "    else:\n",
    "        show_by_hour[hour] = 1\n",
    "        points_by_hour[hour] = points\n",
    "        \n",
    "print('Posts per hour:',show_by_hour)\n",
    "print('\\n')\n",
    "print('Points per hour:',points_by_hour)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['14', 25.430232558139537],\n",
       " ['22', 40.34782608695652],\n",
       " ['18', 36.31147540983606],\n",
       " ['07', 19.0],\n",
       " ['20', 30.316666666666666],\n",
       " ['05', 5.473684210526316],\n",
       " ['16', 28.322580645161292],\n",
       " ['19', 30.945454545454545],\n",
       " ['15', 28.564102564102566],\n",
       " ['03', 25.14814814814815],\n",
       " ['17', 27.107526881720432],\n",
       " ['06', 23.4375],\n",
       " ['02', 11.333333333333334],\n",
       " ['13', 24.626262626262626],\n",
       " ['08', 15.264705882352942],\n",
       " ['21', 18.425531914893618],\n",
       " ['04', 14.846153846153847],\n",
       " ['11', 33.63636363636363],\n",
       " ['12', 41.68852459016394],\n",
       " ['23', 42.388888888888886],\n",
       " ['09', 18.433333333333334],\n",
       " ['01', 25.0],\n",
       " ['10', 18.916666666666668],\n",
       " ['00', 37.83870967741935]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing a list for storing averaged points per post per hour\n",
    "avg_points_post = []\n",
    "for hour in show_by_hour:\n",
    "    post_count = show_by_hour[hour]\n",
    "    post_points = points_by_hour[hour]\n",
    "    \n",
    "    # Average points per post for every hour = no. of points per hour / no. of posts per hour\n",
    "    avg_data =  post_points / post_count\n",
    "    avg_points_post.append([hour,avg_data])\n",
    "\n",
    "avg_points_post\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[42.388888888888886, '23'],\n",
       " [41.68852459016394, '12'],\n",
       " [40.34782608695652, '22'],\n",
       " [37.83870967741935, '00'],\n",
       " [36.31147540983606, '18'],\n",
       " [33.63636363636363, '11'],\n",
       " [30.945454545454545, '19'],\n",
       " [30.316666666666666, '20'],\n",
       " [28.564102564102566, '15'],\n",
       " [28.322580645161292, '16'],\n",
       " [27.107526881720432, '17'],\n",
       " [25.430232558139537, '14'],\n",
       " [25.14814814814815, '03'],\n",
       " [25.0, '01'],\n",
       " [24.626262626262626, '13'],\n",
       " [23.4375, '06'],\n",
       " [19.0, '07'],\n",
       " [18.916666666666668, '10'],\n",
       " [18.433333333333334, '09'],\n",
       " [18.425531914893618, '21'],\n",
       " [15.264705882352942, '08'],\n",
       " [14.846153846153847, '04'],\n",
       " [11.333333333333334, '02'],\n",
       " [5.473684210526316, '05']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a list with swapped values for better readability    \n",
    "swapped = []    \n",
    "for row in avg_points_post:\n",
    "    swapped.append([row[1],row[0]])\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Sorting values in descending order for better accessibility\n",
    "sorted_swap = sorted(swapped,reverse=True)\n",
    "sorted_swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 hours for Show HN posts in Eastern Standard Time\n",
      "23:00 EST: 42.39 average points per post\n",
      "12:00 EST: 41.69 average points per post\n",
      "22:00 EST: 40.35 average points per post\n",
      "00:00 EST: 37.84 average points per post\n",
      "18:00 EST: 36.31 average points per post\n",
      "Hour with least average points: 05:00 EST with 5.47 points\n"
     ]
    }
   ],
   "source": [
    "# Printing the top 5 hours with most points per page\n",
    "print('Top 5 hours for Show HN posts in Eastern Standard Time')\n",
    "for row in sorted_swap[:5]:\n",
    "    print('{}:00 EST: {:.2f} average points per post'.format(row[1],row[0]))\n",
    "\n",
    "# Printing the hour with least points per page\n",
    "print('Hour with least average points: {}:00 EST with {:.2f} points'.format(sorted_swap[-1][1],sorted_swap[-1][0]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 hours for Show HN post in Indian Standard Time\n",
      "09:00 IST: 42.39 average points per post\n",
      "22:00 IST: 41.69 average points per post\n",
      "08:00 IST: 40.35 average points per post\n",
      "10:00 IST: 37.84 average points per post\n",
      "04:00 IST: 36.31 average points per post\n",
      "Hour with least comments: 15:00 IST with 5.47 comments\n"
     ]
    }
   ],
   "source": [
    "# Initializing a list to store IST converted values\n",
    "ist_data_2 = []\n",
    "\n",
    "# Importing 'pytz' module for defining the timezone of original values as 'EST'\n",
    "import pytz\n",
    "for row in sorted_swap:\n",
    "    avg_points = row[0]\n",
    "    time = row[1]\n",
    "    \n",
    "    # Parsing the date from string as hour only \n",
    "    parse_time = dt.datetime.strptime(time,'%H')\n",
    "    \n",
    "    # Replacing the naive 'datetime' object with 'active' datetime object with\n",
    "    # 'UST' timezone\n",
    "    est_tz = parse_time.replace(tzinfo=pytz.timezone('US/Eastern'))\n",
    "    \n",
    "    # Converting the timezone: EST to IST\n",
    "    changed_tz = est_tz.astimezone(pytz.timezone('Asia/Kolkata'))\n",
    "    \n",
    "    # Finally appending the data to the list as formatted string\n",
    "    final_ist = changed_tz.strftime('%H:00')\n",
    "    ist_data_2.append([avg_points,final_ist])\n",
    "\n",
    "# printing the top 5 and the least average number of comments posts\n",
    "print('Top 5 hours for Show HN post in Indian Standard Time')    \n",
    "for row in ist_data_2[:5]:\n",
    "        time_data = row[1]\n",
    "        avg_points = row[0]\n",
    "        print('{} IST: {:.2f} average points per post'.format(time_data,avg_points))\n",
    "print('Hour with least comments: {} IST with {:.2f} comments'.format(ist_data_2[-1][-1],ist_data_2[-1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear from the above output that time between `23:00 and 24:00 EST` `(09:00 and 10:00 IST)` is the best to create a `Show HN` post and receive maximum points. Also, the percentage difference between the hour receiving top and least number of points is around `37%`, which is quite significant. Hence, the timing plays an important role in getting greater points on `Show HN` posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. __Comparing the average number of comments and points for `Ask HN` and `Show HN` posts to all the other posts.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other posts points: [[datetime.datetime(2016, 8, 4, 11, 52), '386'], [datetime.datetime(2016, 1, 26, 19, 30), '39'], [datetime.datetime(2016, 6, 23, 22, 20), '2'], [datetime.datetime(2016, 6, 17, 0, 1), '3'], [datetime.datetime(2015, 9, 30, 4, 12), '8']]\n",
      "\n",
      "\n",
      "Other posts comments: [[datetime.datetime(2016, 8, 4, 11, 52), '52'], [datetime.datetime(2016, 1, 26, 19, 30), '10'], [datetime.datetime(2016, 6, 23, 22, 20), '1'], [datetime.datetime(2016, 6, 17, 0, 1), '1'], [datetime.datetime(2015, 9, 30, 4, 12), '2']]\n",
      "\n",
      "\n",
      "Average points for other posts : 55.41\n",
      "Average comments for other posts : 26.87\n"
     ]
    }
   ],
   "source": [
    "# Initializing lists for storing dates with comments and points seperately\n",
    "other_comments = []\n",
    "other_points = []\n",
    "\n",
    "# Looping over data set of 'other' posts\n",
    "for row in other_posts:\n",
    "    date = dt.datetime.strptime(row[-1],'%m/%d/%Y %H:%M')\n",
    "    points = row[3]\n",
    "    comments = row[4]\n",
    "    \n",
    "    # Appending data to the lists\n",
    "    other_points.append([date,points])\n",
    "    other_comments.append([date,comments])\n",
    "\n",
    "print('Other posts points:',other_points[:5])\n",
    "print('\\n')\n",
    "print('Other posts comments:',other_comments[:5])\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Calculating average points and comments for all the other posts\n",
    "sum_points = 0\n",
    "for row in other_points:\n",
    "    points = int(row[1])\n",
    "    sum_points += points\n",
    "avg_points = sum_points/len(other_points)\n",
    "print('Average points for other posts : {:.2f}'.format(avg_points))\n",
    "\n",
    "sum_comments = 0\n",
    "for row in other_comments:\n",
    "    comments = int(row[1])\n",
    "    sum_comments += comments\n",
    "avg_comments = sum_comments / len(other_comments)\n",
    "print('Average comments for other posts : {:.2f}'.format(avg_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it clear from above, the average points and comments for all other posts which excludes `Ask HN` and `Show HN` posts, seems to greater than their points and comments. \n",
    "* The average points for other posts exceeds that in case the of `Show HN` posts by almost `28%`, and\n",
    "* The average comments for other posts exceeds that in case the of `Ask HN` posts by almost `13%`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other posts per hour: {'11': 660, '19': 980, '22': 758, '00': 611, '04': 454, '09': 534, '16': 1101, '18': 1084, '10': 591, '12': 789, '20': 911, '03': 407, '17': 1169, '14': 958, '13': 918, '01': 500, '23': 674, '08': 496, '02': 441, '21': 874, '15': 1040, '06': 408, '05': 388, '07': 448}\n",
      "\n",
      "\n",
      "Other points per hour: {'11': 37995, '19': 58811, '22': 38079, '00': 35718, '04': 22549, '09': 28802, '16': 59655, '18': 58459, '10': 35746, '12': 45287, '20': 41218, '03': 23167, '17': 67777, '14': 59191, '13': 57398, '01': 25303, '23': 35068, '08': 26830, '02': 25786, '21': 43149, '15': 62964, '06': 18864, '05': 19387, '07': 25461}\n",
      "\n",
      "\n",
      "Other comments per hour: {'11': 19532, '19': 26167, '22': 17635, '00': 16544, '04': 10953, '09': 14732, '16': 27959, '18': 29186, '10': 15728, '12': 23944, '20': 21080, '03': 10918, '17': 32727, '14': 30973, '13': 28363, '01': 11536, '23': 16592, '08': 13405, '02': 12254, '21': 20635, '15': 30700, '06': 8714, '05': 9768, '07': 12010}\n"
     ]
    }
   ],
   "source": [
    "# Initializing dictionaries to make frequency tables for other posts, points\n",
    "# and comments generated per hour\n",
    "points_per_hour = {}\n",
    "comments_per_hour = {}\n",
    "posts_per_hour = {}\n",
    "\n",
    "# Checking whether hour exists in points dictionary as a key-value pair\n",
    "for row in other_points:\n",
    "    hour = row[0].strftime('%H')\n",
    "    points = int(row[1])\n",
    "    if hour in posts_per_hour:\n",
    "        posts_per_hour[hour] += 1\n",
    "        points_per_hour[hour] += points\n",
    "    else:\n",
    "        posts_per_hour[hour] = 1\n",
    "        points_per_hour[hour] = points\n",
    "\n",
    "# Checking whether hour exists in comments dictionary as a key-value pair\n",
    "for row in other_comments:\n",
    "    hour = row[0].strftime('%H')\n",
    "    comments = int(row[1])\n",
    "    if hour in comments_per_hour:\n",
    "        comments_per_hour[hour] += comments\n",
    "    else:\n",
    "        comments_per_hour[hour] = comments\n",
    "\n",
    "print('Other posts per hour:',posts_per_hour)\n",
    "print('\\n')\n",
    "print('Other points per hour:',points_per_hour)\n",
    "print('\\n')\n",
    "print('Other comments per hour:',comments_per_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average points per post per hour\n",
      "['11', 57.56818181818182]\n",
      "['19', 60.01122448979592]\n",
      "['22', 50.236147757255935]\n",
      "['00', 58.4582651391162]\n",
      "['04', 49.66740088105727]\n",
      "['09', 53.93632958801498]\n",
      "['16', 54.182561307901906]\n",
      "['18', 53.928966789667896]\n",
      "['10', 60.4839255499154]\n",
      "['12', 57.3979721166033]\n",
      "['20', 45.24478594950604]\n",
      "['03', 56.92137592137592]\n",
      "['17', 57.97861420017109]\n",
      "['14', 61.78601252609603]\n",
      "['13', 62.525054466230934]\n",
      "['01', 50.606]\n",
      "['23', 52.02967359050445]\n",
      "['08', 54.09274193548387]\n",
      "['02', 58.471655328798185]\n",
      "['21', 49.369565217391305]\n",
      "['15', 60.542307692307695]\n",
      "['06', 46.23529411764706]\n",
      "['05', 49.96649484536083]\n",
      "['07', 56.832589285714285]\n",
      "\n",
      "\n",
      "Average comments per post per hour\n",
      "['11', 29.593939393939394]\n",
      "['19', 26.701020408163266]\n",
      "['22', 23.265171503957784]\n",
      "['00', 27.076923076923077]\n",
      "['04', 24.125550660792953]\n",
      "['09', 27.588014981273407]\n",
      "['16', 25.394187102633968]\n",
      "['18', 26.924354243542435]\n",
      "['10', 26.612521150592215]\n",
      "['12', 30.34727503168568]\n",
      "['20', 23.13940724478595]\n",
      "['03', 26.825552825552826]\n",
      "['17', 27.99572284003422]\n",
      "['14', 32.33089770354906]\n",
      "['13', 30.896514161220043]\n",
      "['01', 23.072]\n",
      "['23', 24.617210682492583]\n",
      "['08', 27.026209677419356]\n",
      "['02', 27.786848072562357]\n",
      "['21', 23.60983981693364]\n",
      "['15', 29.51923076923077]\n",
      "['06', 21.357843137254903]\n",
      "['05', 25.175257731958762]\n",
      "['07', 26.808035714285715]\n"
     ]
    }
   ],
   "source": [
    "# Initializing lists to store averaged points and comments per hour per post\n",
    "average_points = []\n",
    "average_comments = []\n",
    "\n",
    "for hour in posts_per_hour:\n",
    "    \n",
    "    # Average points per post per hour = points per hour / posts per hour\n",
    "    # Average comments per post per hour = comments per hour / posts per hour\n",
    "    avg_points_per_post = points_per_hour[hour] / posts_per_hour[hour]\n",
    "    avg_comments_per_post = comments_per_hour[hour] / posts_per_hour[hour]\n",
    "    \n",
    "    average_points.append([hour,avg_points_per_post])\n",
    "    average_comments.append([hour,avg_comments_per_post])\n",
    "    \n",
    "print('Average points per post per hour')\n",
    "for row in average_points:\n",
    "    print(row)\n",
    "print('\\n')\n",
    "print('Average comments per post per hour')\n",
    "for row in average_comments:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Swapped points:\n",
      "[57.56818181818182, '11']\n",
      "[60.01122448979592, '19']\n",
      "[50.236147757255935, '22']\n",
      "[58.4582651391162, '00']\n",
      "[49.66740088105727, '04']\n",
      "[53.93632958801498, '09']\n",
      "[54.182561307901906, '16']\n",
      "[53.928966789667896, '18']\n",
      "[60.4839255499154, '10']\n",
      "[57.3979721166033, '12']\n",
      "[45.24478594950604, '20']\n",
      "[56.92137592137592, '03']\n",
      "[57.97861420017109, '17']\n",
      "[61.78601252609603, '14']\n",
      "[62.525054466230934, '13']\n",
      "[50.606, '01']\n",
      "[52.02967359050445, '23']\n",
      "[54.09274193548387, '08']\n",
      "[58.471655328798185, '02']\n",
      "[49.369565217391305, '21']\n",
      "[60.542307692307695, '15']\n",
      "[46.23529411764706, '06']\n",
      "[49.96649484536083, '05']\n",
      "[56.832589285714285, '07']\n",
      "\n",
      "\n",
      "Swapped comments:\n",
      "[29.593939393939394, '11']\n",
      "[26.701020408163266, '19']\n",
      "[23.265171503957784, '22']\n",
      "[27.076923076923077, '00']\n",
      "[24.125550660792953, '04']\n",
      "[27.588014981273407, '09']\n",
      "[25.394187102633968, '16']\n",
      "[26.924354243542435, '18']\n",
      "[26.612521150592215, '10']\n",
      "[30.34727503168568, '12']\n",
      "[23.13940724478595, '20']\n",
      "[26.825552825552826, '03']\n",
      "[27.99572284003422, '17']\n",
      "[32.33089770354906, '14']\n",
      "[30.896514161220043, '13']\n",
      "[23.072, '01']\n",
      "[24.617210682492583, '23']\n",
      "[27.026209677419356, '08']\n",
      "[27.786848072562357, '02']\n",
      "[23.60983981693364, '21']\n",
      "[29.51923076923077, '15']\n",
      "[21.357843137254903, '06']\n",
      "[25.175257731958762, '05']\n",
      "[26.808035714285715, '07']\n"
     ]
    }
   ],
   "source": [
    "# Creating swapped lists for above data for better readability\n",
    "swapped_points = []\n",
    "swapped_comments = []\n",
    "\n",
    "for row in average_points:\n",
    "    swapped_points.append([row[1],row[0]])\n",
    "\n",
    "print('\\n')    \n",
    "for row in average_comments:\n",
    "    swapped_comments.append([row[1],row[0]])\n",
    "\n",
    "print('Swapped points:')\n",
    "for row in swapped_points:\n",
    "    print(row)\n",
    "print('\\n')\n",
    "print('Swapped comments:')    \n",
    "for row in swapped_comments:\n",
    "    print(row)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted average points per hour per post:\n",
      "[62.525054466230934, '13']\n",
      "[61.78601252609603, '14']\n",
      "[60.542307692307695, '15']\n",
      "[60.4839255499154, '10']\n",
      "[60.01122448979592, '19']\n",
      "[58.471655328798185, '02']\n",
      "[58.4582651391162, '00']\n",
      "[57.97861420017109, '17']\n",
      "[57.56818181818182, '11']\n",
      "[57.3979721166033, '12']\n",
      "[56.92137592137592, '03']\n",
      "[56.832589285714285, '07']\n",
      "[54.182561307901906, '16']\n",
      "[54.09274193548387, '08']\n",
      "[53.93632958801498, '09']\n",
      "[53.928966789667896, '18']\n",
      "[52.02967359050445, '23']\n",
      "[50.606, '01']\n",
      "[50.236147757255935, '22']\n",
      "[49.96649484536083, '05']\n",
      "[49.66740088105727, '04']\n",
      "[49.369565217391305, '21']\n",
      "[46.23529411764706, '06']\n",
      "[45.24478594950604, '20']\n",
      "\n",
      "\n",
      "Sorted average comments per hour per post:\n",
      "[32.33089770354906, '14']\n",
      "[30.896514161220043, '13']\n",
      "[30.34727503168568, '12']\n",
      "[29.593939393939394, '11']\n",
      "[29.51923076923077, '15']\n",
      "[27.99572284003422, '17']\n",
      "[27.786848072562357, '02']\n",
      "[27.588014981273407, '09']\n",
      "[27.076923076923077, '00']\n",
      "[27.026209677419356, '08']\n",
      "[26.924354243542435, '18']\n",
      "[26.825552825552826, '03']\n",
      "[26.808035714285715, '07']\n",
      "[26.701020408163266, '19']\n",
      "[26.612521150592215, '10']\n",
      "[25.394187102633968, '16']\n",
      "[25.175257731958762, '05']\n",
      "[24.617210682492583, '23']\n",
      "[24.125550660792953, '04']\n",
      "[23.60983981693364, '21']\n",
      "[23.265171503957784, '22']\n",
      "[23.13940724478595, '20']\n",
      "[23.072, '01']\n",
      "[21.357843137254903, '06']\n"
     ]
    }
   ],
   "source": [
    "# Initializing lists to store the sorted data for better accessibility\n",
    "sorted_points = sorted(swapped_points,reverse=True)\n",
    "sorted_comments = sorted(swapped_comments,reverse=True)\n",
    "\n",
    "print('Sorted average points per hour per post:')\n",
    "for row in sorted_points:\n",
    "    print(row)\n",
    "print('\\n')    \n",
    "print('Sorted average comments per hour per post:')\n",
    "for row in sorted_comments:\n",
    "    print(row)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 hours for maximum points on all other posts in Eastern Standard Time\n",
      "13:00 EST: 62.53 average points per post\n",
      "14:00 EST: 61.79 average points per post\n",
      "15:00 EST: 60.54 average points per post\n",
      "10:00 EST: 60.48 average points per post\n",
      "19:00 EST: 60.01 average points per post\n",
      "Hour with least average points: 20:00 EST with 45.24 points\n",
      "\n",
      "\n",
      "Top 5 hours for maximum comments on other posts in Eastern Standard Time\n",
      "14:00 EST: 32.33 average comments per post\n",
      "13:00 EST: 30.90 average comments per post\n",
      "12:00 EST: 30.35 average comments per post\n",
      "11:00 EST: 29.59 average comments per post\n",
      "15:00 EST: 29.52 average comments per post\n",
      "Hour with least average comments: 06:00 EST with 21.36 points\n"
     ]
    }
   ],
   "source": [
    "# Printing the top 5 hours with most points per page for points data above\n",
    "print('Top 5 hours for maximum points on all other posts in Eastern Standard Time')\n",
    "for row in sorted_points[:5]:\n",
    "    print('{}:00 EST: {:.2f} average points per post'.format(row[1],row[0]))\n",
    "\n",
    "# Printing the hour with least points per page\n",
    "print('Hour with least average points: {}:00 EST with {:.2f} points'.format(sorted_points[-1][1],sorted_points[-1][0]))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Printing the top 5 hours with most comments per page for comments data above\n",
    "print('Top 5 hours for maximum comments on other posts in Eastern Standard Time')\n",
    "for row in sorted_comments[:5]:\n",
    "    print('{}:00 EST: {:.2f} average comments per post'.format(row[1],row[0]))\n",
    "\n",
    "# Printing the hour with least points per page\n",
    "print('Hour with least average comments: {}:00 EST with {:.2f} points'.format(sorted_comments[-1][1],sorted_comments[-1][0]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 hours for maximum points on other posts in Indian Standard Time\n",
      "23:00 IST: 62.53 average points per post\n",
      "00:00 IST: 61.79 average points per post\n",
      "01:00 IST: 60.54 average points per post\n",
      "20:00 IST: 60.48 average points per post\n",
      "05:00 IST: 60.01 average points per post\n",
      "Hour with least points: 06:00 IST with 45.24 comments\n",
      "\n",
      "\n",
      "Top 5 hours for maximum comments on other posts in Indian Standard Time\n",
      "00:00 IST: 32.33 average comments per post\n",
      "23:00 IST: 30.90 average comments per post\n",
      "22:00 IST: 30.35 average comments per post\n",
      "21:00 IST: 29.59 average comments per post\n",
      "01:00 IST: 29.52 average comments per post\n",
      "Hour with least comments: 16:00 IST with 21.36 comments\n"
     ]
    }
   ],
   "source": [
    "# Initializing a list to store IST converted values for points data above\n",
    "ist_data_2 = []\n",
    "\n",
    "# Importing 'pytz' module for defining the timezone of original values as 'EST'\n",
    "import pytz\n",
    "for row in sorted_points:\n",
    "    avg_points = row[0]\n",
    "    time = row[1]\n",
    "    \n",
    "    # Parsing the date from string as hour only \n",
    "    parse_time = dt.datetime.strptime(time,'%H')\n",
    "    \n",
    "    # Replacing the naive 'datetime' object with 'active' datetime object with\n",
    "    # 'UST' timezone\n",
    "    est_tz = parse_time.replace(tzinfo=pytz.timezone('US/Eastern'))\n",
    "    \n",
    "    # Converting the timezone: EST to IST\n",
    "    changed_tz = est_tz.astimezone(pytz.timezone('Asia/Kolkata'))\n",
    "    \n",
    "    # Finally appending the data to the list as formatted string\n",
    "    final_ist = changed_tz.strftime('%H:00')\n",
    "    ist_data_2.append([avg_points,final_ist])\n",
    "\n",
    "# printing the top 5 and the least average number of comments posts\n",
    "print('Top 5 hours for maximum points on other posts in Indian Standard Time')\n",
    "for row in ist_data_2[:5]:\n",
    "        time_data = row[1]\n",
    "        avg_points = row[0]\n",
    "        print('{} IST: {:.2f} average points per post'.format(time_data,avg_points))\n",
    "print('Hour with least points: {} IST with {:.2f} comments'.format(ist_data_2[-1][-1],ist_data_2[-1][0]))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Initializing a list to store IST converted values for comments data above\n",
    "ist_data_3 = []\n",
    "for row in sorted_comments:\n",
    "    avg_points = row[0]\n",
    "    time = row[1]\n",
    "    \n",
    "    # Parsing the date from string as hour only \n",
    "    parse_time = dt.datetime.strptime(time,'%H')\n",
    "    \n",
    "    # Replacing the naive 'datetime' object with 'active' datetime object with\n",
    "    # 'UST' timezone\n",
    "    est_tz = parse_time.replace(tzinfo=pytz.timezone('US/Eastern'))\n",
    "    \n",
    "    # Converting the timezone: EST to IST\n",
    "    changed_tz = est_tz.astimezone(pytz.timezone('Asia/Kolkata'))\n",
    "    \n",
    "    # Finally appending the data to the list as formatted string\n",
    "    final_ist = changed_tz.strftime('%H:00')\n",
    "    ist_data_3.append([avg_points,final_ist])\n",
    "\n",
    "# printing the top 5 and the least average number of comments posts\n",
    "print('Top 5 hours for maximum comments on other posts in Indian Standard Time')\n",
    "for row in ist_data_3[:5]:\n",
    "        time_data = row[1]\n",
    "        avg_points = row[0]\n",
    "        print('{} IST: {:.2f} average comments per post'.format(time_data,avg_points))\n",
    "print('Hour with least comments: {} IST with {:.2f} comments'.format(ist_data_3[-1][-1],ist_data_3[-1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above it can be seen that time from `13:00 to 14:00 EST` `(23:00 to 24:00 IST)` and `14:00 to 15:00 EST` `(00:00 to 01:00 IST)` are best for acheiving maximum comments and points on all the posts other than `Ask HN` and `Show HN` posts.\n",
    "\n",
    "It is also worth noting that the percentage differences between the maximum and minimum values of average points and comments per hour per post are about `11%` and `17%`, which are quite less compared to the values we found above in the case of `Ask HN` and `Show HN` posts. This along with greater averaged values for comments and points for the other posts means that all the posts other than `Ask HN` and `Show HN` posts, are much more likely to engage a greater audience at almost all hours of the day"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
